---
title: 'Learning from imbalanced data'
year: 2009
cited_by_count: 3002
authors:
  - Haibo He
  - Edwardo A. Garcia
tags:
  - review
  - classification
  - resampling
  - informed-resampling
  - smote
  - adasyn
  - kernel-based
  - active-learning
  - decision-trees
  - neural-networks
  - tomek-links
  - assessment-metrics
  - cost-sensitive
links:
  - https://ieeexplore.ieee.org/abstract/document/5128907/
summary: |
  - Abstract:
    - A comprehensive review of the development of research in learning from imbalanced data.
    - Includes: nature of the problem, the state-of-the-art technologies, and the current assessment metrics used to evaluate learning performance.
    - Also highlights the major opportunities and challenges, as well as potential important research directions.
  - Introduction:
    - Prevalence and importance of imbalanced data.
    - Informal characterization of the problem.
    - Imbalanced data as a field is growing rapidly.
  - Nature of the problem:
    - Informal definition of between-class imbalance.
    - Between-class imblances can be binary or multiclass, though this paper focuses on binary.
    - More motivation for solving the problem, examples, etc.
    - Intrinsic vs extrinsic imbalances:
      - Intrinsically imbalanced datasets are a result of the nature of the dataspace itself.
      - Extrinsicaly imbalanced datasets may be imbalanced because of variable factors like time and storage space.
    - Relative imbalance vs absolute rarity.
    - Data complexity:
      - Broad term that encompasses a lot.
      - Within-class imbalances, where subconcepts have relatively fewer examples.
      - Small disjuncts created by the classifier for these less well-represented subconcepts.
      - Can be difficult to distinguish between very poorly represented subconcepts and simple random noise.
    - Effects can combine, e.g. commonly with general imbalanced data and the small sample size problem.
  - Solutions:
    - Uses decision trees as an illustrative example.
    - Problems with decision trees (for imbalanced data): reducing examples at each partition.
    - Notational conventions.
    - Sampling methods:
      - Basic description.
      - Typically these methods show improvements for most imbalanced datasets.
      - Random oversampling and undersampling, and the relative potential pitfalls of each.
      - Informed undersampling to address information loss in random undersampling; EasyEnsemble, BalanceCascade, KNN, OSS.
      - Synthetic resampling: SMOTE, how it works, problem of over-generalization.
      - ADASYN to address the over-generalization problem in SMOTE.
      - Resampling with data cleaning: Tomek links, and combination of TL with other methods.
      - Cluster-based sampling method: CBO using K-means.
      - Integration of sampling and boosting.
    - Cost-sensitive methods:
      - Basic idea of assigning costs to misclassified examples.
      - Typically use a pre-defined cost matrix.
      - Can be superior to sampling methods in certain domains, and hence are a viable alternative.
      - Categories of methods: dataspace weighting, ensemble-based, and classifier-incorporated.
      - Cost-sensitive boosting methods.
      - Implementations in decision trees and neural networks.  Brief mention of other classifiers.
    - Kernel-based methods and active learning:
      - Kernel based methods:
        - Based on statistical learning theory (VC)
        - Integration with sampling methods
        - Kernel modification methods.
      - Active learning:
        - Traditionally used for unsupervised learning, but applied to IL
        - Selects most informative instances from unseen training data.
    - Additional methods:
      - One-class learning
      - Autoassociators
      - Etc.
  - Assessment metrics for imbalanced learning:
    - Accuracy/error rate are most frequent for classifier assessment, but have problems with IL.
    - Simple alternatives: precision, recall, F-measure, G-mean. Issues with these.
    - ROC curve to address the issues above.  Limitations of ROC curves.
    - PR to address limitations of ROC curves.
    - Cost curves for confidence intervals and inference.
    - Assessment for multiclass IL.
  - Opportunities and challenges:
    - Increasing availability of large amounts of data enriches opportunities of learning from imbalanced data.
    - Most current work looks at specific algorithms with little work on theoretical underpinnings.
    - Not clear which IL methods (if any) should be used for given data/task.
    - Argues for a generlalist approach to making ML methods.
    - Key questions:
      - 1. What kind of assumptions will make imbalanced learning algorithms work better compared to learning from the original distributions?
      - 2. To what degree should one balance the original data set?
      - 3. How do imbalanced data distributions affect the computational complexity of learning algorithms?
      - 4. What is the general error bound given an imbalanced data distribution?
      - 5. Is there a general theoretical methodology that can alleviate the impediment of learning from imbalanced data sets for specific algorithms and application domains?
    - Lack of and need for a uniform benchmark platform for imbalanced learning.
    - Lack of and need for standardized evaluation practices.
    - Need for work on incremental learning.
    - Need for work on semisupervised learning.
...
